{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUdcapYhVj5e"
      },
      "outputs": [],
      "source": [
        "# Load Data \n",
        "import h5py\n",
        "import json\n",
        "import numpy as np\n",
        "from numpy import argwhere\n",
        "\n",
        "\n",
        "# Open the dataset\n",
        "hdf5_file = h5py.File(\"/content/drive/MyDrive/EGH400-2/Dataset/GOLD_XYZ_OSC.0001_1024.hdf5\",  'r')\n",
        "# Load the modulation classes. You can also copy and paste the content of classes-fixed.txt.\n",
        "modulation_classes = json.load(open(\"/content/drive/MyDrive/EGH400-2/Dataset/classes-fixed.json\", 'r'))\n",
        "\n",
        "\n",
        "# Read the HDF5 groups\n",
        "data = hdf5_file['X'] # Data of length with 2555904 shape 0f (2555904,1024,2) 106496 dataset for each modulation, Starting point of zero noise level: 41000 for each data\n",
        "modulation_onehot = hdf5_file['Y'] # Data which include name of modulation methods, length with 2555904\n",
        "snr = hdf5_file['Z'] # noise level of data ,length with 2555904 (Max:30 , Min:-20)\n",
        "\n",
        "class_name = ['OOK', '4ASK', '8ASK', 'BPSK', 'QPSK', '8PSK', '16PSK', '32PSK', '16APSK', '32APSK', '64APSK', '128APSK', '16QAM', '32QAM', '64QAM', '128QAM', '256QAM', 'AM-SSB-WC', 'AM-SSB-SC', 'AM-DSB-WC', 'AM-DSB-SC', 'FM', 'GMSK', 'OQPSK']\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsB6Twwnb3aA"
      },
      "outputs": [],
      "source": [
        "# Preprosessing data\n",
        "\n",
        "n = 12500 # Numbers of samples for each modulation method\n",
        "\n",
        "\n",
        "new_data = np.zeros(shape= (n*24,1024,2) ) # Create zeros array to store fileted data\n",
        "new_modulation = np.zeros(shape = (n*24,24) ) # Create zeros array to store fileted data\n",
        "\n",
        "  \n",
        "\n",
        "# Store low noise level data to zeros array.\n",
        "for i in range(0,24):\n",
        "  new_data[i*n:i*n+n] = data[i*106496 + 41000 : i*106496+ 41000 + n ]\n",
        "  new_modulation[i*n:i*n+n] = modulation_onehot[i*106496 + 41000:i*106496+ 41000 + n]\n",
        "\n",
        "\n",
        "new_data = new_data*0.1 # Rescaling data -2 ~ 2 to -0.2 ~ 2 \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_06JvFnDTfFm"
      },
      "outputs": [],
      "source": [
        "# Split the Data to Train & Test set\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Convert data to numpy array to split dataset for training and testing (validation).\n",
        "x = np.array(new_data)\n",
        "y = np.array(new_modulation)\n",
        "\n",
        "# Divide data to train and test. 15 percent of datasts is used to validation and test \n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, \n",
        "                                                      test_size = 0.15,\n",
        "                                                      random_state = 1,\n",
        "                                                      shuffle = True,\n",
        "                                                      stratify = y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0mnRjpvKjDA"
      },
      "outputs": [],
      "source": [
        "#Implement Model \n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time  \n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0],512,2,2)\n",
        "x_test = x_test.reshape(x_test.shape[0],512,2,2)\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    \n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal', input_shape = (512, 2, 2)), \n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1), \n",
        "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1), \n",
        "    tf.keras.layers.Conv2D( 32, (2,2), padding = \"same\", activation = \"relu\", input_shape = (512,2,2)),    \n",
        "    tf.keras.layers.MaxPooling2D( (2,2) ),  \n",
        "    tf.keras.layers.BatchNormalization(axis = -1 ),  \n",
        "    tf.keras.layers.Dropout(0.5),      \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation = 'relu'),         \n",
        "    tf.keras.layers.Dense(1024, activation = 'relu'),           \n",
        "    tf.keras.layers.Dense(1024, activation = 'relu'),           \n",
        "    tf.keras.layers.Dense(1024, activation = 'relu'),          \n",
        "    tf.keras.layers.Dense(1024, activation = 'relu'),    \n",
        "    tf.keras.layers.Dense(1024, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(1024, activation = 'relu'),       \n",
        "    tf.keras.layers.Dense(1024, activation = 'relu'),          \n",
        "    tf.keras.layers.Dense(1024, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(1024, activation = 'relu'), \n",
        "    tf.keras.layers.Dense(1024, activation = 'relu'), \n",
        "    tf.keras.layers.Dense(1024, activation = 'relu'),                                 \n",
        "    tf.keras.layers.Dense(24, activation = 'softmax') \n",
        "    \n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "tensorboard = TensorBoard( log_dir = 'logs/{}'.format('Model' + str( int(time.time()) ) ))\n",
        "\n",
        "es = EarlyStopping( monitor = 'val_loss', patience = 5)\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
        "model.fit(x_train ,y_train,validation_data = (x_test,y_test) ,epochs = 300, callbacks = [ tensorboard , es ])\n",
        "\n",
        "result = model.evaluate([x_test],[y_test]) \n",
        "print(result)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY4_SgLf-nE7"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2PtSMCP-p_0"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1TN-H3_KxUcafT6HsN-2NuTbD4mOn95tg",
      "authorship_tag": "ABX9TyPwv6ktVQlK+bNTgJEMiyNU"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}